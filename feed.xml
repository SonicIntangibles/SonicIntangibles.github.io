<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://sonicintangibles.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://sonicintangibles.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-03-26T09:43:50+00:00</updated><id>https://sonicintangibles.github.io/feed.xml</id><title type="html">Sonic Intangibles</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Paper of The Week</title><link href="https://sonicintangibles.github.io/stories/2025/POTW/" rel="alternate" type="text/html" title="Paper of The Week"/><published>2025-03-18T00:00:00+00:00</published><updated>2025-03-18T00:00:00+00:00</updated><id>https://sonicintangibles.github.io/stories/2025/POTW</id><content type="html" xml:base="https://sonicintangibles.github.io/stories/2025/POTW/"><![CDATA[<p>Each week the Sonic Intangibles team select a paper to read and discuss. Paper number two is:</p> <p>S. Pauletto and Y. Seznec (2024). Connecting Sound to Data: Sonification Workshop Methods With Expert and Non-Expert Participants, J. Audio Eng. Soc. Vol. 72, np. 5, pp. 328-340. <a href="https://doi.org/10.17743/jaes.2022.0143">DOI:10.17743/jaes.2022.0143</a>.</p>]]></content><author><name></name></author><category term="paper-of-the-week"/><summary type="html"><![CDATA[Each week the Sonic Intangibles team select a paper to read and discuss. Paper number two is:]]></summary></entry><entry><title type="html">Paper of The Week</title><link href="https://sonicintangibles.github.io/stories/2025/POTW/" rel="alternate" type="text/html" title="Paper of The Week"/><published>2025-03-11T00:00:00+00:00</published><updated>2025-03-11T00:00:00+00:00</updated><id>https://sonicintangibles.github.io/stories/2025/POTW</id><content type="html" xml:base="https://sonicintangibles.github.io/stories/2025/POTW/"><![CDATA[<p>Each week the Sonic Intangibles team select a paper to read and discuss. We are starting with:</p> <p>Akkerman, S.F. and Bakker, A., 2011. Boundary crossing and boundary objects. Review of educational research, 81(2), pp.132-169. <a href="https://doi.org/10.3102/0034654311404435">DOI:10.3102/0034654311404435</a>.</p> <p>It opens with the quote:</p> <blockquote> <p>I am conscious of myself and become myself only while revealing myself for another, through another, and with the help of another. … [E]very internal experience ends up on the boundary. Bakhtin (1984, p. 287)</p> </blockquote>]]></content><author><name></name></author><category term="paper-of-the-week"/><summary type="html"><![CDATA[Each week the Sonic Intangibles team select a paper to read and discuss. We are starting with:]]></summary></entry><entry><title type="html">Direct Segmented Sonification</title><link href="https://sonicintangibles.github.io/stories/2024/DSSon/" rel="alternate" type="text/html" title="Direct Segmented Sonification"/><published>2024-07-23T14:12:00+00:00</published><updated>2024-07-23T14:12:00+00:00</updated><id>https://sonicintangibles.github.io/stories/2024/DSSon</id><content type="html" xml:base="https://sonicintangibles.github.io/stories/2024/DSSon/"><![CDATA[<p>Paul Vickers and Robert Höldrich presented <em>Direct Segmented Sonification</em>, or DSSon <a class="citation" href="#Vickers:2019b">(Vickers &amp; Höldrich, 2019)</a> as a way of sonifying one-dimensional time series data in a temporally compressed form that picks out key features in the data.</p> <p>Data was gathered from <a href="https://paulvickers.github.io/SoniFRED/">users on the FRED machine</a>. Below are two examples of using DSSon.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/assets/audio/DSSon_ADV_B_n.mp3" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/assets/audio/DSSon_ADV_A_e.mp3" controls=""/> </figure> </div> </div> <div class="caption"> The first example is a DSSOn of one minute of a first-time user's data. The second one is one minute of data taken from an expert user. </div> <p>The DSSon here emphasised <em>poor technique</em>, so the less sound you hear, the better the user is operating the machine.</p>]]></content><author><name></name></author><category term="previous-work"/><category term="audio"/><summary type="html"><![CDATA[Sonifying one-dimensional time-series data]]></summary></entry></feed>