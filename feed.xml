<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://sonicintangibles.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://sonicintangibles.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-06-29T16:42:50+00:00</updated><id>https://sonicintangibles.github.io/feed.xml</id><title type="html">Sonic Intangibles</title><subtitle>A website for the Sonic Intangibles project. </subtitle><entry><title type="html">Week 2 Blog Post</title><link href="https://sonicintangibles.github.io/log/2025/student-blog-2/" rel="alternate" type="text/html" title="Week 2 Blog Post"/><published>2025-06-17T00:00:00+00:00</published><updated>2025-06-17T00:00:00+00:00</updated><id>https://sonicintangibles.github.io/log/2025/student-blog-2</id><content type="html" xml:base="https://sonicintangibles.github.io/log/2025/student-blog-2/"><![CDATA[<h1 id="sonification-week-2-blog-post">Sonification Week 2 Blog Post</h1> <h2 id="week-2-project-aims">Week 2 Project Aims</h2> <p>Our aim for this week was to start exploring how we might sonify one of our initial ideas created in week 1: the collision of two black holes.</p> <p>We wanted Week 2 to focus on developing our skills and confidence in using the coding programme Strauss and some musical outputs such as synthesisers, Pure Data, and Ableton Live to sonify our chosen topic through data. The group also decided to consider what we wanted the sonification’s purpose to be and how we could strategically tailor the output to successfully engage people from any background, education, and age.</p> <h2 id="summary-of-week-2">Summary of Week 2</h2> <p>After spending the first week of the project brainstorming and becoming familiar with each other, our skills, and working styles, we decided to jump into week two by using our varied skill set to explore the idea of sonifying data using Strauss and later synthesisers and Ableton Live.</p> <ul> <li> <p>On Monday, we decided to have an independent research day as to allow us to become more familiar with the field of sonification as a whole. We all separately investigated the methods and tools others had used to create successful sonifications, focusing on the conversion of data to sound but also the communication of the sonifications, making them accessible through features such as visual aids, narration and text.</p> </li> <li> <p>In our meeting on the following day, we discussed our thoughts and findings from our independent research before going ahead with exploring the collision of two black holes idea in more detail. We found some LIGO data about gravitational waves from a suspected blackholes collision and plotted a graph of the frequency (of the gravitational waves) against time with Strauss. We mapped the frequency to pitch to create a sonification and then attempted to apply different methods to auditorily emphasise the intense change in the data, but we ran into a few issues with the coding. Oliver also brought his synthesiser to the meeting and so continued our exploration of the extent to which data can be interpreted as musical.</p> </li> <li> <p>On Wednesday, we had an informal meeting with our supervisors to discuss our progress and the initial ideas we have been exploring. This was an insightful meeting as the supervisors not only answered our questions on our issues with Strauss, but Jorge also helped us realise we have the freedom to interpret our data as creatively as we desire. We collectively felt they had given us the tools to move forward with our project, as well as outlined some ideas we could explore, such as using speakers to create an experience of our data through vibrations through the floor, and the application of pure data to support the sonification.</p> </li> <li> <p>On Thursday, we managed to build off and apply the advice from our supervisors, successfully solving our coding problems by resampling the data and applying a filter cut-off to best emphasise the change in the data. We also discussed how to approach the final output of our sonification, collectively developing the idea of having separated speakers vibrating two data sets across the floor, coming into a collision to represent the collision of the black holes. Similarly, we considered the idea that a visual aid projected across the floor would support the auditory experience.</p> </li> <li> <p>On Friday, we explored the sonification through the music programme Ableton Live. We converted the WAV file into a MIDI file and started to explore how the different musical effects, such as volume, panning, reverb and distortion devices, manipulated the interpretation of the data. Most noticeably, we imputed synthetic instrumental sounds onto the data and were intrigued by how the change in timbre made us automatically perceive the data in a more musical form than it had been when it was sonified by Strauss.</p> </li> </ul> <h2 id="black-hole-sonification">Black Hole Sonification:</h2> <p>After coming together on Tuesday to discuss our findings from our independent study day, we decided to explore the idea of sonifying two black holes colliding.</p> <p>To begin this process, we obtained some gravitational wave data and plotted the graph that you can see below:</p> <p><img src="https://newcastle-my.sharepoint.com/:i:/g/personal/c3035389_newcastle_ac_uk/EXqTwJ1lUCVDrtCBCfD-HBkBZIg_Sf5W_y1niNBW56dzAw?e=d1nMvQ" alt=""/></p> <p>We then, after some issues with coding, mapped pitch to the frequency values of the graph to create a successful sonification of the data.</p> <p>We ran into a few problems with the coding due to the amount of data that was available, so we tried several methods to adjust the material, including our attempt to sonify the original image of the data, as seen below. Ultimately, after implementing the suggestions from our supervisors, we managed to input the data into a more suitable form by resampling the data and applying a low-frequency filter cutoff to aid in emphasising the intense change in the data. This sonification can be heard below:</p> <p><img src="https://newcastle-my.sharepoint.com/:i:/g/personal/c3035389_newcastle_ac_uk/EfZp6mrNwixKuRcJKcAH0EkB3opWXj7kgiP8z2xeVXv28g?e=MjP3xF" alt=""/></p> <p><a href="https://newcastle-my.sharepoint.com/:u:/g/personal/c3035389_newcastle_ac_uk/EdToW2WrwrxCk9d4YcH9hc4BdQbnevbaffmDIYna-b7Oxw?nav=eyJyZWZlcnJhbEluZm8iOnsicmVmZXJyYWxBcHAiOiJPbmVEcml2ZUZvckJ1c2luZXNzIiwicmVmZXJyYWxBcHBQbGF0Zm9ybSI6IldlYiIsInJlZmVycmFsTW9kZSI6InZpZXciLCJyZWZlcnJhbFZpZXciOiJNeUZpbGVzTGlua0NvcHkifX0&amp;e=rG5RH3">Cut in half Black Hole graph</a>.</p> <p>We also explored Oliver’s use of his synthesiser, using a range of techniques and effects to investigate the musical potential of sound created through data. Here are some of his explorations below:</p> <p><a href="https://newcastle-my.sharepoint.com/:u:/g/personal/c3035389_newcastle_ac_uk/EbPwKlIzJi5Dm2vk2AG5pAkBKL06YJxhsjMWw2H7Bf6VTA?nav=eyJyZWZlcnJhbEluZm8iOnsicmVmZXJyYWxBcHAiOiJPbmVEcml2ZUZvckJ1c2luZXNzIiwicmVmZXJyYWxBcHBQbGF0Zm9ybSI6IldlYiIsInJlZmVycmFsTW9kZSI6InZpZXciLCJyZWZlcnJhbFZpZXciOiJNeUZpbGVzTGlua0NvcHkifX0&amp;e=UL57uC">STE-016.wav</a>. <a href="https://newcastle-my.sharepoint.com/:u:/g/personal/c3035389_newcastle_ac_uk/EW54Sa_tdRFBqzG2_5ftl8wBbwC8BulFCNwngPp4K4F2EA?nav=eyJyZWZlcnJhbEluZm8iOnsicmVmZXJyYWxBcHAiOiJPbmVEcml2ZUZvckJ1c2luZXNzIiwicmVmZXJyYWxBcHBQbGF0Zm9ybSI6IldlYiIsInJlZmVycmFsTW9kZSI6InZpZXciLCJyZWZlcnJhbFZpZXciOiJNeUZpbGVzTGlua0NvcHkifX0&amp;e=QVCm5s">STE-017.wav</a>. <a href="https://newcastle-my.sharepoint.com/:u:/g/personal/c3035389_newcastle_ac_uk/Ebf5ipNIIMNHkyvkthr4rpMBjrgRqj-PjttjbN2uetQmIg?nav=eyJyZWZlcnJhbEluZm8iOnsicmVmZXJyYWxBcHAiOiJPbmVEcml2ZUZvckJ1c2luZXNzIiwicmVmZXJyYWxBcHBQbGF0Zm9ybSI6IldlYiIsInJlZmVycmFsTW9kZSI6InZpZXciLCJyZWZlcnJhbFZpZXciOiJNeUZpbGVzTGlua0NvcHkifX0&amp;e=eHh36O">STE-015.wav</a>.</p> <p>After we had successfully sonified the data in Strauss, we began to explore with it in Ableton Live. We thought this software would give us a wider range of effects and a more interpretive tactile approach to manipulating the data than Strauss. We used a range of effects with a focus on emphasizing the original data but merging it with a creative musical element through using a synthesised instrument and layering the data in contrasting ways. The use of Ableton Live gave us more creative freedom with the data and was useful in showing us the potential of the data that we couldn’t see whilst it was in Strauss. Here is our first creative modification of the data in Ableton Live:</p> <p><a href="https://newcastle-my.sharepoint.com/:u:/g/personal/c3035389_newcastle_ac_uk/EV1_SOJh2bpEqt3dcys7sfEBFN8WBZS0XAANjAo0LAJaJQ?nav=eyJyZWZlcnJhbEluZm8iOnsicmVmZXJyYWxBcHAiOiJPbmVEcml2ZUZvckJ1c2luZXNzIiwicmVmZXJyYWxBcHBQbGF0Zm9ybSI6IldlYiIsInJlZmVycmFsTW9kZSI6InZpZXciLCJyZWZlcnJhbFZpZXciOiJNeUZpbGVzTGlua0NvcHkifX0&amp;e=IJ5Wa7">Sonification.mp3</a>.</p> <h2 id="week-2-interdisciplinary-teamwork">Week 2: Interdisciplinary Teamwork</h2> <p>Below is a summary of how we felt our teamworking skills have developed and been challenged across week 2, aided by some student quotes.</p> <p>This week we continued to develop and strengthen our rhythm as a team in this project. We have continued to work well together, with everyone showing enthusiasm and respect for the project through individual work, idea creation, and collaborative decision making.</p> <p>Through everyone’s interest in the project, we managed to find a topic that everyone was excited to explore, which led to more idea creation as well as motivation.</p> <p>However, something all students found ‘challenging’ and ‘frustrating’ throughout this week was dealing with our technical issues with the coding. We found that a trial-and-error attitude and positive mindset kept the group working to find a solution without feeling dejected by a lack of quick progress. Thanks to our resilience, we managed to work out the problem, which felt ‘like a big achievement’ after a few days of working on it.</p> <p>One change that was unintentionally implemented this week was that on Thursday, instead of notesbooks each student brought an individual laptop to the meeting. Despite being a coincidence, this resulted in a more productive meeting as each student could work on their own research or exploration related to the project, whilst still being able to communicate with the other students on the main task at hand. This is something that would be useful to employ for the remainder of the week as it increases productivity but also team spirit, as each member can contribute to group discussions, but also work independently when their expertise is not the focus of the session.</p> <p>One feature of our interdisciplinary group that was carried over from last week was the students’ struggle to understand certain aspects of each other’s expertise. This was most apparent from the Humanities students at the beginning of the week, as they felt ‘useless’ and ‘frustrated’ over their lack of understanding of coding elements and therefore minimal contribution to solving the coding issues. However, theses feelings shifted to the Physics students on Friday when they felt ‘a little out of their depth’ when confronted with unfamiliar music software.</p> <p>However, both sets of students highlighted that they felt ‘respected’ and ‘supported throughout the week and expressed that they helped one another understand the other’s expertise, so the group was always on the same page. This sharing of information highlighted once again the benefit of this being an interdisciplinary project, as we have all expressed multiple times across the week that we were glad that we had different expertise and how we would not have been able to complete the project without our varied set of skills.</p> <p>## Aims for Week 3</p> <p>After our session on Friday, when we creatively worked with the data in Ableton Live, group members felt they were in a ‘good position’ and felt ‘excited’ to continue experimenting with ‘different interpretations’ and ideas, already ‘thinking about how we can further develop the basis we created’ on Friday.</p> <p>Some avenues we are going to explore are: placing speakers in such a way that their sounds intersect, mirroring the experience of the collision sonically as well as working with panning techniques and potential sources for visual aids.</p>]]></content><author><name></name></author><category term="student-blog,"/><category term="reflection"/><summary type="html"><![CDATA[Sonification Week 2 Blog Post Week 2 Project Aims Our aim for this week was to start exploring how we might sonify one of our initial ideas created in week 1: the collision of two black holes. We wanted Week 2 to focus on developing our skills and confidence in using the coding programme Strauss and some musical outputs such as synthesisers, Pure Data, and Ableton Live to sonify our chosen topic through data. The group also decided to consider what we wanted the sonification’s purpose to be and how we could strategically tailor the output to successfully engage people from any background, education, and age. Summary of Week 2 After spending the first week of the project brainstorming and becoming familiar with each other, our skills, and working styles, we decided to jump into week two by using our varied skill set to explore the idea of sonifying data using Strauss and later synthesisers and Ableton Live. On Monday, we decided to have an independent research day as to allow us to become more familiar with the field of sonification as a whole. We all separately investigated the methods and tools others had used to create successful sonifications, focusing on the conversion of data to sound but also the communication of the sonifications, making them accessible through features such as visual aids, narration and text. In our meeting on the following day, we discussed our thoughts and findings from our independent research before going ahead with exploring the collision of two black holes idea in more detail. We found some LIGO data about gravitational waves from a suspected blackholes collision and plotted a graph of the frequency (of the gravitational waves) against time with Strauss. We mapped the frequency to pitch to create a sonification and then attempted to apply different methods to auditorily emphasise the intense change in the data, but we ran into a few issues with the coding. Oliver also brought his synthesiser to the meeting and so continued our exploration of the extent to which data can be interpreted as musical. On Wednesday, we had an informal meeting with our supervisors to discuss our progress and the initial ideas we have been exploring. This was an insightful meeting as the supervisors not only answered our questions on our issues with Strauss, but Jorge also helped us realise we have the freedom to interpret our data as creatively as we desire. We collectively felt they had given us the tools to move forward with our project, as well as outlined some ideas we could explore, such as using speakers to create an experience of our data through vibrations through the floor, and the application of pure data to support the sonification. On Thursday, we managed to build off and apply the advice from our supervisors, successfully solving our coding problems by resampling the data and applying a filter cut-off to best emphasise the change in the data. We also discussed how to approach the final output of our sonification, collectively developing the idea of having separated speakers vibrating two data sets across the floor, coming into a collision to represent the collision of the black holes. Similarly, we considered the idea that a visual aid projected across the floor would support the auditory experience. On Friday, we explored the sonification through the music programme Ableton Live. We converted the WAV file into a MIDI file and started to explore how the different musical effects, such as volume, panning, reverb and distortion devices, manipulated the interpretation of the data. Most noticeably, we imputed synthetic instrumental sounds onto the data and were intrigued by how the change in timbre made us automatically perceive the data in a more musical form than it had been when it was sonified by Strauss. Black Hole Sonification: After coming together on Tuesday to discuss our findings from our independent study day, we decided to explore the idea of sonifying two black holes colliding. To begin this process, we obtained some gravitational wave data and plotted the graph that you can see below: We then, after some issues with coding, mapped pitch to the frequency values of the graph to create a successful sonification of the data. We ran into a few problems with the coding due to the amount of data that was available, so we tried several methods to adjust the material, including our attempt to sonify the original image of the data, as seen below. Ultimately, after implementing the suggestions from our supervisors, we managed to input the data into a more suitable form by resampling the data and applying a low-frequency filter cutoff to aid in emphasising the intense change in the data. This sonification can be heard below: Cut in half Black Hole graph. We also explored Oliver’s use of his synthesiser, using a range of techniques and effects to investigate the musical potential of sound created through data. Here are some of his explorations below: STE-016.wav. STE-017.wav. STE-015.wav. After we had successfully sonified the data in Strauss, we began to explore with it in Ableton Live. We thought this software would give us a wider range of effects and a more interpretive tactile approach to manipulating the data than Strauss. We used a range of effects with a focus on emphasizing the original data but merging it with a creative musical element through using a synthesised instrument and layering the data in contrasting ways. The use of Ableton Live gave us more creative freedom with the data and was useful in showing us the potential of the data that we couldn’t see whilst it was in Strauss. Here is our first creative modification of the data in Ableton Live: Sonification.mp3. Week 2: Interdisciplinary Teamwork Below is a summary of how we felt our teamworking skills have developed and been challenged across week 2, aided by some student quotes. This week we continued to develop and strengthen our rhythm as a team in this project. We have continued to work well together, with everyone showing enthusiasm and respect for the project through individual work, idea creation, and collaborative decision making. Through everyone’s interest in the project, we managed to find a topic that everyone was excited to explore, which led to more idea creation as well as motivation. However, something all students found ‘challenging’ and ‘frustrating’ throughout this week was dealing with our technical issues with the coding. We found that a trial-and-error attitude and positive mindset kept the group working to find a solution without feeling dejected by a lack of quick progress. Thanks to our resilience, we managed to work out the problem, which felt ‘like a big achievement’ after a few days of working on it. One change that was unintentionally implemented this week was that on Thursday, instead of notesbooks each student brought an individual laptop to the meeting. Despite being a coincidence, this resulted in a more productive meeting as each student could work on their own research or exploration related to the project, whilst still being able to communicate with the other students on the main task at hand. This is something that would be useful to employ for the remainder of the week as it increases productivity but also team spirit, as each member can contribute to group discussions, but also work independently when their expertise is not the focus of the session. One feature of our interdisciplinary group that was carried over from last week was the students’ struggle to understand certain aspects of each other’s expertise. This was most apparent from the Humanities students at the beginning of the week, as they felt ‘useless’ and ‘frustrated’ over their lack of understanding of coding elements and therefore minimal contribution to solving the coding issues. However, theses feelings shifted to the Physics students on Friday when they felt ‘a little out of their depth’ when confronted with unfamiliar music software. However, both sets of students highlighted that they felt ‘respected’ and ‘supported throughout the week and expressed that they helped one another understand the other’s expertise, so the group was always on the same page. This sharing of information highlighted once again the benefit of this being an interdisciplinary project, as we have all expressed multiple times across the week that we were glad that we had different expertise and how we would not have been able to complete the project without our varied set of skills. ## Aims for Week 3 After our session on Friday, when we creatively worked with the data in Ableton Live, group members felt they were in a ‘good position’ and felt ‘excited’ to continue experimenting with ‘different interpretations’ and ideas, already ‘thinking about how we can further develop the basis we created’ on Friday. Some avenues we are going to explore are: placing speakers in such a way that their sounds intersect, mirroring the experience of the collision sonically as well as working with panning techniques and potential sources for visual aids.]]></summary></entry><entry><title type="html">test</title><link href="https://sonicintangibles.github.io/log/2025/test/" rel="alternate" type="text/html" title="test"/><published>2025-06-17T00:00:00+00:00</published><updated>2025-06-17T00:00:00+00:00</updated><id>https://sonicintangibles.github.io/log/2025/test</id><content type="html" xml:base="https://sonicintangibles.github.io/log/2025/test/"><![CDATA[<h1 id="testing-soundcloud">Testing soundcloud</h1> <iframe width="100%" height="166" scrolling="no" frameborder="no" allow="autoplay" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/2109970440&amp;color=%23a1a8a9&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true"></iframe> <div style="font-size: 10px; color: #CCCCCC;line-break: anywhere;word-break: normal;overflow: hidden;white-space: nowrap;text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif;font-weight: 100;"><a href="https://soundcloud.com/audio-universe-685767042" title="Audio Universe" target="_blank" style="color: #CCCCCC; text-decoration: none;">Audio Universe</a> · <a href="https://soundcloud.com/audio-universe-685767042/audio-universe-tour-of-the-solar-system-flying-music" title="Audio Universe: Tour of the Solar System (Flying Music)" target="_blank" style="color: #CCCCCC; text-decoration: none;">Audio Universe: Tour of the Solar System (Flying Music)</a></div>]]></content><author><name></name></author><summary type="html"><![CDATA[Testing soundcloud]]></summary></entry><entry><title type="html">Week 1 Blog Post</title><link href="https://sonicintangibles.github.io/log/2025/student-blog-1/" rel="alternate" type="text/html" title="Week 1 Blog Post"/><published>2025-06-06T00:00:00+00:00</published><updated>2025-06-06T00:00:00+00:00</updated><id>https://sonicintangibles.github.io/log/2025/student-blog-1</id><content type="html" xml:base="https://sonicintangibles.github.io/log/2025/student-blog-1/"><![CDATA[<h1 id="sonification-week-1-blog-post">Sonification Week 1 Blog Post</h1> <h2 id="introduction-to-our-project">Introduction to our project</h2> <p>Our goal for this project is to explore how we can represent otherwise intangible media using sound. Specfically, we’d like to explore an astrophysical phenomena and repesent it in a more tangible way.</p> <p>There are four students working on this project: two astrophysics students, one music student, and one fine art student. As well as developing a final sonification for this project, our overall goal is to also focus on how we work as an interdisciplinary team. We all have very different knowledge backgrounds, and aim to apply our skillsets to acheive a collective, more well-rounded project.</p> <h2 id="summary-of-week-1">Summary of Week 1</h2> <p>Our aim for the first week was to get to know one another and explore our initial ideas. From the start, we were all very excited to get started working together as an interdisciplinary team. The prospect of combining physics and data in a creative way was something we found very intriguing.</p> <p>The first week of our four week project focused on getting to know one another and laying down a foundation for our initial ideas.</p> <ul> <li>Day 1 began with our first team meeting since the start of the project where we got to know one another and began brainstorming our initial ideas whilst exploring the resources provided</li> <li>The second day was dedicated to further developing these ideas, and discussing potential directions that our project could take</li> <li>On the third day of the project we met with our project supervisors, where they gave us a brief overview of the field of Sonification and guided us towards some potential approaches we could take. We also completed a Strauss workshop to help us with our project.</li> <li>On days 4 and 5, we focused on attempting to make our Sonifcation using real galaxy data using Strauss. We also experimented with a synthesiser to outline another method we could use to sonify data.</li> </ul> <h2 id="our-initial-ideas-and-first-sonification">Our initial ideas and first sonification</h2> <p>After exploring many different avenues, we collectively decided that we’d like to use Sonifcation to explore astrophysical data. Some of our initial ideas included: tracking the evolution of a galaxy through its main sequence and subsequent red giant/wite dwarf branch, and exploring what happens to a particle approaching a black hole from multiple observation points.</p> <p>To begin with, we wanted to plot a basic graph using some real data to allow us to experiment with the sound that can be produced from this. To do this, we decided to use a subset of galaxy data that the physics students had used for a previous course. We took the redshift and colour indices of 500 galaxies from this set. The graph below shows the data plotted as colour index against redshift:</p> <p><img src="/assets/img/blog1_fig1.png" alt=""/></p> <p>To attempt our first Sonifcation, we took only the u-band and plotted this against redshift. We then used Strauss to treat each data point as an event that producees its own sound to make an overall representation of the amplitude of the graph using a varying pitch for each data point. The graph, and accompanying Sonifcation can be seen below:</p> <p><img src="/assets/img/blog1_fig2.png" alt=""/></p> <p><a href="https://newcastle.sharepoint.com/:u:/s/SonificationSummerProject2025/EUwCvtlG5nlDlCVJJTTvTBsBxgeW6JOLKB_pjb9YAnckaQ?e=IdXmvk">link to Sonifcation </a>.</p> <h2 id="thoughts-and-feelings-after-the-first-week">Thoughts and feelings after the first week</h2> <p>Below is a brief summary of how we felt starting this project, with some quotes from each of the students.</p> <p>We all found the first meeting ‘initially a little awkward’ as an interdisciplinary project of this sort was very new for all of us, but we ‘quickly managed to find overlap in each of our interests, coming up with ideas and starting points - bouncing ideas off of each other.’ We also found it quite ‘daunting’ and were a bit aprehensive as the project ‘seemed far more open-ended’ than we had perhaps anticipated.</p> <p>The non-physics students found the coding aspect of this week ‘challenging’ as this was something they hadn’t worked with before. Whilst the physics students found the more creative and artistic aspect ‘harder to grasp and interpret’.</p> <p>However, seeing each persons respective fields overlap helped us to all feel more ‘comfortable and highlighted the positive nature of this interdisciplinary project’.</p> <p>Overall, the group feels very excited and motivated going forward, and we look forward to expanding upon our initial ideas in more detail.</p>]]></content><author><name></name></author><category term="student-blog,"/><category term="reflection"/><summary type="html"><![CDATA[Sonification Week 1 Blog Post Introduction to our project Our goal for this project is to explore how we can represent otherwise intangible media using sound. Specfically, we’d like to explore an astrophysical phenomena and repesent it in a more tangible way. There are four students working on this project: two astrophysics students, one music student, and one fine art student. As well as developing a final sonification for this project, our overall goal is to also focus on how we work as an interdisciplinary team. We all have very different knowledge backgrounds, and aim to apply our skillsets to acheive a collective, more well-rounded project. Summary of Week 1 Our aim for the first week was to get to know one another and explore our initial ideas. From the start, we were all very excited to get started working together as an interdisciplinary team. The prospect of combining physics and data in a creative way was something we found very intriguing. The first week of our four week project focused on getting to know one another and laying down a foundation for our initial ideas. Day 1 began with our first team meeting since the start of the project where we got to know one another and began brainstorming our initial ideas whilst exploring the resources provided The second day was dedicated to further developing these ideas, and discussing potential directions that our project could take On the third day of the project we met with our project supervisors, where they gave us a brief overview of the field of Sonification and guided us towards some potential approaches we could take. We also completed a Strauss workshop to help us with our project. On days 4 and 5, we focused on attempting to make our Sonifcation using real galaxy data using Strauss. We also experimented with a synthesiser to outline another method we could use to sonify data. Our initial ideas and first sonification After exploring many different avenues, we collectively decided that we’d like to use Sonifcation to explore astrophysical data. Some of our initial ideas included: tracking the evolution of a galaxy through its main sequence and subsequent red giant/wite dwarf branch, and exploring what happens to a particle approaching a black hole from multiple observation points. To begin with, we wanted to plot a basic graph using some real data to allow us to experiment with the sound that can be produced from this. To do this, we decided to use a subset of galaxy data that the physics students had used for a previous course. We took the redshift and colour indices of 500 galaxies from this set. The graph below shows the data plotted as colour index against redshift: To attempt our first Sonifcation, we took only the u-band and plotted this against redshift. We then used Strauss to treat each data point as an event that producees its own sound to make an overall representation of the amplitude of the graph using a varying pitch for each data point. The graph, and accompanying Sonifcation can be seen below: link to Sonifcation . Thoughts and feelings after the first week Below is a brief summary of how we felt starting this project, with some quotes from each of the students. We all found the first meeting ‘initially a little awkward’ as an interdisciplinary project of this sort was very new for all of us, but we ‘quickly managed to find overlap in each of our interests, coming up with ideas and starting points - bouncing ideas off of each other.’ We also found it quite ‘daunting’ and were a bit aprehensive as the project ‘seemed far more open-ended’ than we had perhaps anticipated. The non-physics students found the coding aspect of this week ‘challenging’ as this was something they hadn’t worked with before. Whilst the physics students found the more creative and artistic aspect ‘harder to grasp and interpret’. However, seeing each persons respective fields overlap helped us to all feel more ‘comfortable and highlighted the positive nature of this interdisciplinary project’. Overall, the group feels very excited and motivated going forward, and we look forward to expanding upon our initial ideas in more detail.]]></summary></entry><entry><title type="html">Pint of Science</title><link href="https://sonicintangibles.github.io/log/2025/pos/" rel="alternate" type="text/html" title="Pint of Science"/><published>2025-05-14T00:00:00+00:00</published><updated>2025-05-14T00:00:00+00:00</updated><id>https://sonicintangibles.github.io/log/2025/pos</id><content type="html" xml:base="https://sonicintangibles.github.io/log/2025/pos/"><![CDATA[<p>On the 21st of May the Sonic Intangibles team (in collaboration with <a href="https://pintofscience.co.uk/">Pint of Science</a>) are hosting an evening dedicated to sonification. The evening is titled “The Sounds of Science” and will be held at <a href="https://thecommonroom.org.uk/programme/">The Common Room</a>. Aimed at a public audience, we will will take a sonic journey through science with talks and performances that represent a broad range of fleeting physical and biological phenomena through sound — from distant galaxies, to brain signals and Earth cycles. For more information please see the <a href="https://pintofscience.co.uk/event/the-sounds-of-science">event page</a>.</p>]]></content><author><name>Lucy Whalley</name></author><summary type="html"><![CDATA[On the 21st of May the Sonic Intangibles team (in collaboration with Pint of Science) are hosting an evening dedicated to sonification. The evening is titled “The Sounds of Science” and will be held at The Common Room. Aimed at a public audience, we will will take a sonic journey through science with talks and performances that represent a broad range of fleeting physical and biological phenomena through sound — from distant galaxies, to brain signals and Earth cycles. For more information please see the event page.]]></summary></entry><entry><title type="html">Paper of The Fortnight</title><link href="https://sonicintangibles.github.io/log/2025/POTF/" rel="alternate" type="text/html" title="Paper of The Fortnight"/><published>2025-05-11T00:00:00+00:00</published><updated>2025-05-11T00:00:00+00:00</updated><id>https://sonicintangibles.github.io/log/2025/POTF</id><content type="html" xml:base="https://sonicintangibles.github.io/log/2025/POTF/"><![CDATA[<p>Each fortnight a member of the Sonic Intangibles team select a paper to read and discuss. Our reading list is below:</p> <ol> <li> <p>Akkerman, S.F. and Bakker, A., 2011. Boundary crossing and boundary objects. Review of educational research, 81(2), pp.132-169. <a href="https://doi.org/10.3102/0034654311404435">DOI:10.3102/0034654311404435</a>.</p> </li> <li> <p>S. Pauletto and Y. Seznec (2024). Connecting Sound to Data: Sonification Workshop Methods With Expert and Non-Expert Participants, J. Audio Eng. Soc. Vol. 72, np. 5, pp. 328-340. <a href="https://doi.org/10.17743/jaes.2022.0143">DOI:10.17743/jaes.2022.0143</a>.</p> </li> <li> <p>Drever, J.L. (2019). Primacy of the Ear” – But Whose Ear?: The case for auraldiversity in sonic arts practice and discourse, Organised Sound, 24(1), pp. 85–95. <a href="https://doi.org/10.1017/S1355771819000086">doi:10.1017/S1355771819000086</a>.</p> </li> <li> <p>Seiça, M., Roque, L., Martins, P. et al. (2023) An interdisciplinary journey towards an aesthetics of sonification experience. J Multimodal User Interfaces 17, 263–284. <a href="https://doi.org/10.1007/s12193-023-00416-7">DOI:10.1007/s12193-023-00416-7</a></p> </li> <li> <p>Wirfs-Brock, J., Perera, J. and Geere, D., 2024, July. Open sonifications: a manifesto for many ecologies of data and sound. In Proceedings of the 2024 ACM Designing Interactive Systems Conference (pp. 2660-2674). <a href="https://dl.acm.org/doi/10.1145/3643834.3660757">DOI:10.1145/3643834.3660757</a></p> </li> <li> <p>Supper, A. (2012). Lobbying for the ear : the public fascination with and academic legitimacy of the sonification of scientific data. [Doctoral Thesis, Maastricht University]. Datawyse / Universitaire Pers Maastricht. <a href="https://doi.org/10.26481/dis.20120606as">DOI:10.26481/dis.20120606as</a> pages 92-101 (section 3.3)</p> </li> <li> <p>Archer MO, et al. (2022) Listening to the Magnetosphere: How Best to Make ULF Waves Audible. Front. Astron. Space Sci. 9:877172. <a href="https://doi.org/10.3389/fspas.2022.877172">DOI:10.3389/fspas.2022.877172</a></p> </li> </ol>]]></content><author><name></name></author><category term="paper-of-the-fortnight"/><summary type="html"><![CDATA[Each fortnight a member of the Sonic Intangibles team select a paper to read and discuss. Our reading list is below:]]></summary></entry><entry><title type="html">Project Start</title><link href="https://sonicintangibles.github.io/log/2024/start/" rel="alternate" type="text/html" title="Project Start"/><published>2024-12-05T00:00:00+00:00</published><updated>2024-12-05T00:00:00+00:00</updated><id>https://sonicintangibles.github.io/log/2024/start</id><content type="html" xml:base="https://sonicintangibles.github.io/log/2024/start/"><![CDATA[<p>The project will officially begin on 1 February, 2025. Howver, be sure to check back before then for news of preliminary activities and calls for participation that we will be putting out in the New Year.</p>]]></content><author><name>Paul Vickers</name></author><summary type="html"><![CDATA[The project will officially begin on 1 February, 2025. Howver, be sure to check back before then for news of preliminary activities and calls for participation that we will be putting out in the New Year.]]></summary></entry><entry><title type="html">Funding Announcement</title><link href="https://sonicintangibles.github.io/log/2024/CRCRM/" rel="alternate" type="text/html" title="Funding Announcement"/><published>2024-09-02T10:00:00+00:00</published><updated>2024-09-02T10:00:00+00:00</updated><id>https://sonicintangibles.github.io/log/2024/CRCRM</id><content type="html" xml:base="https://sonicintangibles.github.io/log/2024/CRCRM/"><![CDATA[<p>Sonic Intangibles is one of two projects led by Northumbria to be selected for funding in the neww <a href="https://www.ukri.org/news/first-projects-from-ukris-new-interdisciplinary-scheme-announced/">UKRI cross research council responsive mode pilot scheme</a> designed to stimulate exciting new interdisciplinary research across nine different research councils.</p> <blockquote class="block-tip"> <p><a href="https://www.northumbria.ac.uk/about-us/our-staff/v/paul-vickers/">Paul Vickers</a>, Professor of Sonification in <a href="https://www.northumbria.ac.uk/about-us/academic-departments/computer-and-information-sciences/">Computer and Information Sciences</a>, will lead a study with researchers from Northumbria and Newcastle universities which will create a new hub for sonification innovation.<br/> <br/></p> <p>Sonification is a way of communicating information through sound. While human vision can only focus on one thing at a time, we can track multiple sound sources at once, from any direction, and we can understand and feel different things through sound.<br/> <br/></p> <p>After using sonification to transform computer network traffic into nature sounds, Professor Vickers was recently able to discover a new method of cyber-attack. He generated a soundscape that represented the network’s real-time environment and listening to it led to the discovery of a new cyber-attack that had penetrated network defences.<br/> <br/></p> <p>His study will bring together experts in areas such as spatial audio, music, astronomy, culture, materials science and mathematics to explore intangible phenomena through sound. Its aim is to break down interdisciplinary barriers and open new ways of understanding through sound, making the North East a world-leading hub in sonification research.<br/> <br/></p> <p>Professor Vickers explained: “Listening is not limited to the ear – it is inter-sensory and transmodal. We can perceive non-sonic attributes, feel noise in our bodies and we can infer information about intangible things we cannot see by the noises they make, for example, unusual sounds made by a car’s brakes tell us a mechanic is needed.<br/> <br/></p> <p>“Sonification lets us select data that we wish to explore or monitor and attach sounds to it, thus bringing the intangible such as distant galaxies, computer network traffic or the earth’s magnetosphere into our audible experience.”<br/> <br/> — <a href="https://www.northumbria.ac.uk/about-us/news-events/news/lead-poisoning-and-sonic-innovation/">Northumbria University Press Release</a></p> </blockquote>]]></content><author><name></name></author><category term="announcements"/><category term="funding"/><summary type="html"><![CDATA[Sonic Intangibles is one of UKRI’s new interdisciplinary scheme projects]]></summary></entry><entry><title type="html">Direct Segmented Sonification</title><link href="https://sonicintangibles.github.io/log/2024/DSSon/" rel="alternate" type="text/html" title="Direct Segmented Sonification"/><published>2024-07-23T14:12:00+00:00</published><updated>2024-07-23T14:12:00+00:00</updated><id>https://sonicintangibles.github.io/log/2024/DSSon</id><content type="html" xml:base="https://sonicintangibles.github.io/log/2024/DSSon/"><![CDATA[<p>Paul Vickers and Robert Höldrich presented <em>Direct Segmented Sonification</em>, or DSSon <a class="citation" href="#Vickers:2019b">(Vickers &amp; Höldrich, 2019)</a> as a way of sonifying one-dimensional time series data in a temporally compressed form that picks out key features in the data.</p> <p>Data was gathered from <a href="https://paulvickers.github.io/SoniFRED/">users on the FRED machine</a>. Below are two examples of using DSSon.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/assets/audio/DSSon_ADV_B_n.mp3" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/assets/audio/DSSon_ADV_A_e.mp3" controls=""/> </figure> </div> </div> <div class="caption"> The first example is a DSSOn of one minute of a first-time user's data. The second one is one minute of data taken from an expert user. </div> <p>The DSSon here emphasised <em>poor technique</em>, so the less sound you hear, the better the user is operating the machine.</p>]]></content><author><name></name></author><category term="previous-work"/><category term="audio"/><summary type="html"><![CDATA[Sonifying one-dimensional time-series data]]></summary></entry><entry><title type="html">We’re hiring post-doctoral researchers!</title><link href="https://sonicintangibles.github.io/log/2024/hiring/" rel="alternate" type="text/html" title="We’re hiring post-doctoral researchers!"/><published>2024-07-19T00:00:00+00:00</published><updated>2024-07-19T00:00:00+00:00</updated><id>https://sonicintangibles.github.io/log/2024/hiring</id><content type="html" xml:base="https://sonicintangibles.github.io/log/2024/hiring/"><![CDATA[<h2 id="recruitment-closed">RECRUITMENT CLOSED</h2> <p><strong>These positions have now been filled. Thanks to all who applied.</strong></p> <p>The project needs two post-doctoral researchers to play a leading role in the project activities. One post will be based at Northumbria University and the other at neighbouring Newcastle University. Please follow the links below to see each of the job advertisements:</p> <p>We are seeking two researchers, one at Northumbria University and one at neighbouring Newcastle University, to play a central role in this exciting interdisciplinary project that brings together researchers from a range of fields (Music, Computer Science, Astronomy, Mathematics, Space Weather, and Materials Science) to work on developing sonification solutions as a truly interdisciplinary activity.</p> <p>Northumbria University and Newcastle University are both located in Newcastle-upon-Tyne in north-east England, UK. The project team is based at both universities and are within 5–10 minutes’ walk of each other.</p> <p>The project is expected to commence in January 2025. Click on the links below to apply for either position:</p> <ul> <li><a href="https://work4.northumbria.ac.uk/#en/sites/CX_1001/job/2601">Northumbria University: Research Fellow in Computer Science (Sonic Intangibles)</a> — If you would like an informal discussion about the role, please contact the Project Lead, Professor Paul Vickers at paul.vickers@northumbria.ac.uk</li> <li><a href="https://jobs.ncl.ac.uk/job/Newcastle-Research-Associate-Sonic-Intangibles/1095690301/">Newcastle University Research Associate: Sonic Intangibles</a> — For an informal discussion about this post please contact Dr Bennett Hogg at bennett.hogg@ncl.ac.uk.</li> </ul> <p>To apply you will need to include a <strong>covering letter</strong> and a <strong>CV</strong> that includes <strong>a full list of your publications/outputs</strong>.</p> <p>The closing date for applications for both posts is <strong>6 October</strong> and interviews are expected to take place in the <strong>week beginning 21 October</strong>.</p>]]></content><author><name>Paul Vickers</name></author><summary type="html"><![CDATA[RECRUITMENT CLOSED These positions have now been filled. Thanks to all who applied.]]></summary></entry></feed>