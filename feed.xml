<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://sonicintangibles.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://sonicintangibles.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-05-14T08:52:43+00:00</updated><id>https://sonicintangibles.github.io/feed.xml</id><title type="html">Sonic Intangibles</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Paper of The Week</title><link href="https://sonicintangibles.github.io/stories/2025/POTW/" rel="alternate" type="text/html" title="Paper of The Week"/><published>2025-03-25T00:00:00+00:00</published><updated>2025-03-25T00:00:00+00:00</updated><id>https://sonicintangibles.github.io/stories/2025/POTW</id><content type="html" xml:base="https://sonicintangibles.github.io/stories/2025/POTW/"><![CDATA[<p>Each week the Sonic Intangibles team select a paper to read and discuss. Paper number three is:</p> <p>Drever, J.L. (2019). Primacy of the Ear” – But Whose Ear?: The case for auraldiversity in sonic arts practice and discourse, Organised Sound, 24(1), pp. 85–95. <a href="https://doi.org/10.1017/S1355771819000086">doi:10.1017/S1355771819000086</a>.</p>]]></content><author><name></name></author><category term="paper-of-the-week"/><summary type="html"><![CDATA[Each week the Sonic Intangibles team select a paper to read and discuss. Paper number three is:]]></summary></entry><entry><title type="html">Paper of The Week</title><link href="https://sonicintangibles.github.io/stories/2025/POTW/" rel="alternate" type="text/html" title="Paper of The Week"/><published>2025-03-18T00:00:00+00:00</published><updated>2025-03-18T00:00:00+00:00</updated><id>https://sonicintangibles.github.io/stories/2025/POTW</id><content type="html" xml:base="https://sonicintangibles.github.io/stories/2025/POTW/"><![CDATA[<p>Each week the Sonic Intangibles team select a paper to read and discuss. Paper number two is:</p> <p>S. Pauletto and Y. Seznec (2024). Connecting Sound to Data: Sonification Workshop Methods With Expert and Non-Expert Participants, J. Audio Eng. Soc. Vol. 72, np. 5, pp. 328-340. <a href="https://doi.org/10.17743/jaes.2022.0143">DOI:10.17743/jaes.2022.0143</a>.</p>]]></content><author><name></name></author><category term="paper-of-the-week"/><summary type="html"><![CDATA[Each week the Sonic Intangibles team select a paper to read and discuss. Paper number two is:]]></summary></entry><entry><title type="html">Direct Segmented Sonification</title><link href="https://sonicintangibles.github.io/stories/2024/DSSon/" rel="alternate" type="text/html" title="Direct Segmented Sonification"/><published>2024-07-23T14:12:00+00:00</published><updated>2024-07-23T14:12:00+00:00</updated><id>https://sonicintangibles.github.io/stories/2024/DSSon</id><content type="html" xml:base="https://sonicintangibles.github.io/stories/2024/DSSon/"><![CDATA[<p>Paul Vickers and Robert Höldrich presented <em>Direct Segmented Sonification</em>, or DSSon <a class="citation" href="#Vickers:2019b">(Vickers &amp; Höldrich, 2019)</a> as a way of sonifying one-dimensional time series data in a temporally compressed form that picks out key features in the data.</p> <p>Data was gathered from <a href="https://paulvickers.github.io/SoniFRED/">users on the FRED machine</a>. Below are two examples of using DSSon.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/assets/audio/DSSon_ADV_B_n.mp3" controls=""/> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <audio src="/assets/audio/DSSon_ADV_A_e.mp3" controls=""/> </figure> </div> </div> <div class="caption"> The first example is a DSSOn of one minute of a first-time user's data. The second one is one minute of data taken from an expert user. </div> <p>The DSSon here emphasised <em>poor technique</em>, so the less sound you hear, the better the user is operating the machine.</p>]]></content><author><name></name></author><category term="previous-work"/><category term="audio"/><summary type="html"><![CDATA[Sonifying one-dimensional time-series data]]></summary></entry></feed>